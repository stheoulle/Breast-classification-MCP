{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Multi-Input, Multi-Task Model\n",
    "# ==============================\n",
    "\n",
    "### I. Setup\n",
    "import os, glob\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================\n",
    "# II. Select Training Mode\n",
    "# ==============================\n",
    "# \"image\" → BUSI dataset (3 classes)\n",
    "# \"textual\" → breast_cancer dataset (2 classes)\n",
    "training_mode = \"image\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================\n",
    "# III. Image Data (BUSI dataset)\n",
    "# ==============================\n",
    "train_data = \"Dataset_BUSI_with_GT\"\n",
    "\n",
    "image_size = (256, 256)\n",
    "batch_size = 16\n",
    "\n",
    "train_files = [i for i in glob.glob(train_data + \"/*/*\")]\n",
    "labels = [os.path.dirname(i).split(\"/\")[-1] for i in train_files]\n",
    "training_data = pd.DataFrame({\"Path\": train_files, \"Label\": labels})\n",
    "\n",
    "train_df, val_df = train_test_split(training_data, train_size=0.8, shuffle=True, random_state=123)\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_img_gen = datagen.flow_from_dataframe(\n",
    "    train_df, x_col=\"Path\", y_col=\"Label\",\n",
    "    target_size=image_size, class_mode=\"categorical\",\n",
    "    shuffle=True, batch_size=batch_size\n",
    ")\n",
    "val_img_gen = datagen.flow_from_dataframe(\n",
    "    val_df, x_col=\"Path\", y_col=\"Label\",\n",
    "    target_size=image_size, class_mode=\"categorical\",\n",
    "    shuffle=True, batch_size=batch_size\n",
    ")\n",
    "\n",
    "num_img_classes = len(train_img_gen.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================\n",
    "# IV. Textual Data (sklearn breast_cancer)\n",
    "# ==============================\n",
    "dataset = load_breast_cancer()\n",
    "X_tab, Y_tab = dataset.data, dataset.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_tab = scaler.fit_transform(X_tab)\n",
    "\n",
    "X_tab_train, X_tab_val, Y_tab_train, Y_tab_val = train_test_split(\n",
    "    X_tab, Y_tab, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "num_tab_features = X_tab.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================\n",
    "# V. Build Multi-Task Model\n",
    "# ==============================\n",
    "\n",
    "# Image branch\n",
    "image_input = Input(shape=(256, 256, 3), name=\"image_input\")\n",
    "base_model = DenseNet121(weights=\"imagenet\", include_top=False, input_tensor=image_input)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "x_img = Flatten()(base_model.output)\n",
    "x_img = Dense(512, activation=\"relu\")(x_img)\n",
    "x_img = Dropout(0.5)(x_img)\n",
    "img_output = Dense(num_img_classes, activation=\"softmax\", name=\"img_output\")(x_img)\n",
    "\n",
    "# Tabular branch\n",
    "tabular_input = Input(shape=(num_tab_features,), name=\"tabular_input\")\n",
    "x_tab = Dense(64, activation=\"relu\")(tabular_input)\n",
    "x_tab = Dropout(0.3)(x_tab)\n",
    "x_tab = Dense(32, activation=\"relu\")(x_tab)\n",
    "txt_output = Dense(1, activation=\"sigmoid\", name=\"txt_output\")(x_tab)\n",
    "\n",
    "# Multi-task model\n",
    "multi_model = Model(inputs=[image_input, tabular_input], outputs=[img_output, txt_output])\n",
    "multi_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\"img_output\": \"categorical_crossentropy\", \"txt_output\": \"binary_crossentropy\"},\n",
    "    metrics={\"img_output\": \"accuracy\", \"txt_output\": \"accuracy\"}\n",
    ")\n",
    "multi_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================\n",
    "# VI. Training\n",
    "# ==============================\n",
    "\n",
    "if training_mode == \"image\":\n",
    "    # Extract numpy arrays from generators (concatenate batches)\n",
    "    X_img_train = np.concatenate([train_img_gen[i][0] for i in range(len(train_img_gen))], axis=0)\n",
    "    Y_img_train = np.concatenate([train_img_gen[i][1] for i in range(len(train_img_gen))], axis=0)\n",
    "\n",
    "    X_img_val = np.concatenate([val_img_gen[i][0] for i in range(len(val_img_gen))], axis=0)\n",
    "    Y_img_val = np.concatenate([val_img_gen[i][1] for i in range(len(val_img_gen))], axis=0)\n",
    "\n",
    "    history = multi_model.fit(\n",
    "        [X_img_train, np.zeros((len(X_img_train), num_tab_features))],\n",
    "        {\"img_output\": Y_img_train, \"txt_output\": np.zeros((len(X_img_train), 1))},\n",
    "        validation_data=(\n",
    "            [X_img_val, np.zeros((len(X_img_val), num_tab_features))],\n",
    "            {\"img_output\": Y_img_val, \"txt_output\": np.zeros((len(X_img_val), 1))}\n",
    "        ),\n",
    "        epochs=10, batch_size=batch_size\n",
    "    )\n",
    "\n",
    "elif training_mode == \"textual\":\n",
    "    history = multi_model.fit(\n",
    "        [np.zeros((len(X_tab_train), 256, 256, 3)), X_tab_train],\n",
    "        {\"img_output\": np.zeros((len(X_tab_train), num_img_classes)), \"txt_output\": Y_tab_train},\n",
    "        validation_data=(\n",
    "            [np.zeros((len(X_tab_val), 256, 256, 3)), X_tab_val],\n",
    "            {\"img_output\": np.zeros((len(X_tab_val), num_img_classes)), \"txt_output\": Y_tab_val}\n",
    "        ),\n",
    "        epochs=30, batch_size=batch_size\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================\n",
    "# VII. Evaluation\n",
    "# ==============================\n",
    "if training_mode == \"image\":\n",
    "    preds = multi_model.predict([X_img_val, np.zeros((len(X_img_val), num_tab_features))])\n",
    "    y_true = np.argmax(Y_img_val, axis=1)\n",
    "    y_pred = np.argmax(preds[0], axis=1)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=list(train_img_gen.class_indices.keys()),\n",
    "                yticklabels=list(train_img_gen.class_indices.keys()))\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Image Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nClassification Report (Images):\")\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "elif training_mode == \"textual\":\n",
    "    preds = multi_model.predict([np.zeros((len(X_tab_val), 256, 256, 3)), X_tab_val])\n",
    "    y_true = Y_tab_val\n",
    "    y_pred = (preds[1] > 0.5).astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Benign','Malignant'], yticklabels=['Benign','Malignant'])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Textual Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nClassification Report (Textual):\")\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1209633,
     "sourceId": 2021025,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4256535,
     "sourceId": 7332376,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "biogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
